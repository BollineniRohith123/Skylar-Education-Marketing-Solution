import { GoogleGenAI } from "@google/genai";

const apiKey = process.env.API_KEY || '';
const ai = new GoogleGenAI({ apiKey });

/**
 * Uses Gemini 2.5 Flash Image (Nano Banana) to edit the user's photo based on a text prompt.
 * This effectively performs the "Face to Doctor" transformation by instructing the model
 * to change the clothing and environment while keeping the face.
 */
export const transformUserImage = async (
  base64Image: string,
  promptInstruction: string
): Promise<string> => {
  if (!apiKey) {
    throw new Error("API Key is missing. Please set process.env.API_KEY.");
  }

  try {
    // Remove data URL prefix if present to get raw base64
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg);base64,/, "");

    const model = 'gemini-2.5-flash-image';

    // We send the image + the text instruction to "Edit" the image.
    // The prompt is crucial here. We phrase it as an instruction.
    const fullPrompt = `Transform this person's image with the following specifications: ${promptInstruction}

CRITICAL: Keep the person's original face, facial structure, eyes, nose, mouth, and natural expression EXACTLY as they appear in the original photo. Only transform the clothing/outfit and background environment.

Technical requirements: Maintain natural human anatomy and proportions, realistic skin texture with pores and natural tones, authentic fabric materials with proper draping and wrinkles, professional photography quality with proper exposure and natural depth of field, photorealistic rendering, 8k resolution.`;

    const response = await ai.models.generateContent({
      model: model,
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: 'image/jpeg',
              data: cleanBase64
            }
          },
          {
            text: fullPrompt
          }
        ]
      }
    });

    // Parse response to find the generated image
    // gemini-2.5-flash-image usually returns the image in the parts
    const candidates = response.candidates;
    if (candidates && candidates.length > 0) {
      const parts = candidates[0].content.parts;
      for (const part of parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/jpeg;base64,${part.inlineData.data}`;
        }
      }
    }

    throw new Error("No image generated by the model.");

  } catch (error) {
    console.error("Gemini Generation Error:", error);
    throw error;
  }
};
